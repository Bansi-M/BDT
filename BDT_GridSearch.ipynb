{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BDT - Background and Signal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "signal_all = pd.DataFrame()\n",
    "signal_mass = [300, 420, 440, 460, 500, 600, 700, 800, 900, 1000, 1200, 1400, 1600, 2000]\n",
    "for each in signal_mass:\n",
    "    df_temp = pd.read_csv(str(each) + \".csv\", index_col=0)\n",
    "    df_temp_subset = df_temp.sample(n = 3020) #Taking a subset of signals so they are all equal\n",
    "    df_temp_subset.drop(columns=[\"nTags\", \"MCChannelNumber\", \"mVHres\"], inplace=True)\n",
    "    signal_all = pd.concat([df_temp_subset, signal_all], ignore_index=True)\n",
    "     \n",
    "    \n",
    "signal_one = pd.read_csv('500.csv', index_col=0)\n",
    "#signal_one = pd.read_csv('300.csv', index_col=0)\n",
    "signal_one.drop([\"nTags\", \"MCChannelNumber\", \"mVHres\"], axis=1, inplace=True)\n",
    "    \n",
    "background = pd.read_csv(\"background.csv\", index_col=0)\n",
    "background.drop([\"nTags\", \"MCChannelNumber\", \"mVHres\"], axis=1, inplace=True)\n",
    "\n",
    "background = background[background[\"weight\"]>0 ] #Only positive Bkg Weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train_test_split on signals and bkg separately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bkg, test_bkg = train_test_split(background, test_size=0.4, random_state=2) #splitting bkg into train and test\n",
    "train_signal, test_signal = train_test_split(signal_all, test_size=0.4, random_state=2) #splitting signal into train and test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change the weights of training signal so the sum is the same as that of bkg:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_signal_weight = train_signal[\"weight\"] * np.sum(train_bkg[\"weight\"])/np.sum(train_signal[\"weight\"])\n",
    "\n",
    "test_signal_weight = signal_one[\"weight\"] * np.sum(test_bkg[\"weight\"])/np.sum(signal_one[\"weight\"])\n",
    "    \n",
    "test_bkg_weight = test_bkg[\"weight\"].to_numpy()\n",
    "\n",
    "train_bkg_weight = train_bkg[\"weight\"].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine train_signal and train_bkg:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = len(train_bkg) * [0] + len(train_signal) * [1]\n",
    "test_y = len(test_bkg) * [0] + len(signal_one) * [1] \n",
    "\n",
    "train_x = pd.concat([train_bkg, train_signal], ignore_index=True) \n",
    "test_x = pd.concat([test_bkg, signal_one], ignore_index=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assign the weights to a different variable and drop weights from train_x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_weight = train_x[\"weight\"].to_numpy()\n",
    "test_weight = test_x[\"weight\"].to_numpy()\n",
    "\n",
    "train_x.drop([\"weight\"], axis=1, inplace=True)\n",
    "test_x.drop([\"weight\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using GridSearchCV to optimise the BDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters = {'n_estimators': [50,100,300,500,700,900,1000,1500,2000,2500,3000],  \n",
    "#              'base_estimator__max_depth': [1, 2, 3, 4, 5], \n",
    "#              'learning_rate':[0.1, 0.3, 0.5, 1, 1.5,2]} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_gridsearch():\n",
    "    BDT_clf = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(), algorithm=\"SAMME\")\n",
    "    parameters = {'n_estimators': [50,100],  \n",
    "              'base_estimator__max_depth': [1, 2], \n",
    "              'learning_rate':[0.1, 0.3]}\n",
    "    grid = GridSearchCV(BDT_clf, parameters)\n",
    "    grid.fit(train_x, train_y, train_weight)\n",
    "    print(grid.best_params_) \n",
    "    \n",
    "test_gridsearch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
